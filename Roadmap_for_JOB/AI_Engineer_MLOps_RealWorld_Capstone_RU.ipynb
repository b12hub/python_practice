{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# üèóÔ∏è –†–µ–∞–ª—å–Ω—ã–π –º–∏–Ω–∏‚Äë–ø—Ä–æ–µ–∫—Ç AI Engineer + MLOps ‚Äî Capstone (HARD)\n",
    "\n",
    "–î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å –≤ —Å–ª–æ–∂–Ω—ã–π, –ø—Ä–∞–∫—Ç–∏–∫–æ‚Äë–æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –º–∏–Ω–∏‚Äë–ø—Ä–æ–µ–∫—Ç, –∫–æ—Ç–æ—Ä—ã–π –æ—Ç—Ä–∞–∂–∞–µ—Ç –∑–∞–¥–∞—á–∏ —Ä–µ–∞–ª—å–Ω—ã—Ö AI‚Äë–∏–Ω–∂–µ–Ω–µ—Ä–æ–≤ –∏ MLOps‚Äë—Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–æ–≤.\n",
    "\n",
    "–¶–µ–ª—å: —Å–æ–±—Ä–∞—Ç—å –ø—Ä–æ—Ç–æ—Ç–∏–ø –ø—Ä–æ–¥–∞–∫—à–Ω‚Äë—Å–µ—Ä–≤–∏—Å–∞ ML –æ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–æ –¥–µ–ø–ª–æ—è: –ø–∞–π–ø–ª–∞–π–Ω –æ–±—Ä–∞–±–æ—Ç–∫–∏, —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞ —Å —Ç—Ä–µ–∫–∏–Ω–≥–æ–º —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤, —É–ø–∞–∫–æ–≤–∫–∞ –º–æ–¥–µ–ª–∏, REST‚ÄëAPI, –ø–∞–∫–µ—Ç–Ω—ã–π –∏–Ω—Ñ–µ—Ä–µ–Ω—Å, –æ—Å–Ω–æ–≤—ã –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –∏ –Ω–∞–º—ë—Ç–∫–∏ CI/CD.\n",
    "\n",
    "–¢–µ–º–∞—Ç–∏–∫–∞ –ø—Ä–æ–µ–∫—Ç–∞: –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –æ—Ç—Ç–æ–∫–∞ –∫–ª–∏–µ–Ω—Ç–æ–≤ (Churn Prediction) –∫–∞–∫ —Å–µ—Ä–≤–∏—Å.\n",
    "\n",
    "–ß—Ç–æ –≤—ã —Å–¥–µ–ª–∞–µ—Ç–µ:\n",
    "- –ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ –∏ –ø—Ä–æ–≤–µ—Ä–∏—Ç–µ –∫–∞—á–µ—Å—Ç–≤–æ (data validation).\n",
    "- –ü–æ—Å—Ç—Ä–æ–∏—Ç–µ —Ñ–∏—á–µ–ø–∞–π–ø–ª–∞–π–Ω –∏ –º–æ–¥–µ–ª—å (sklearn Pipeline + GridSearch/Opt).\n",
    "- –ó–∞—Ñ–∏–∫—Å–∏—Ä—É–µ—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã/–º–µ—Ç—Ä–∏–∫–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ MLflow).\n",
    "- –°–æ—Ö—Ä–∞–Ω–∏—Ç–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã –º–æ–¥–µ–ª–∏.\n",
    "- –°–∫–æ–Ω—Å—Ç—Ä—É–∏—Ä—É–µ—Ç–µ REST‚ÄëAPI —á–µ—Ä–Ω–æ–≤–∏–∫ (FastAPI).\n",
    "- –ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç–µ –ø–∞–∫–µ—Ç–Ω—ã–π –∏–Ω—Ñ–µ—Ä–µ–Ω—Å.\n",
    "- –ü—Ä–æ–ø–∏—à–µ—Ç–µ Dockerfile (—à–∞–±–ª–æ–Ω) –∏ –∏–¥–µ–∏ –¥–ª—è CI/CD.\n",
    "- –î–æ–±–∞–≤–∏—Ç–µ –±–∞–∑–æ–≤—ã–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ –ø—Ä–æ–≤–µ—Ä–∫—É –¥—Ä–µ–π—Ñ–∞ –¥–∞–Ω–Ω—ã—Ö.\n",
    "\n",
    "üî• –£—Ä–æ–≤–µ–Ω—å: –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π. –≠—Ç–æ ¬´–±–ª–∏–∂–µ –∫ —Ä–µ–∞–ª—å–Ω–æ–π —Ä–∞–±–æ—Ç–µ¬ª, —á–µ–º —É—á–µ–±–Ω—ã–µ –∑–∞–¥–∞—á–∫–∏.\n"
   ],
   "id": "aca588f0decb31f4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## üß≠ –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –∏ —ç—Ç–∞–ø—ã\n",
    "```\n",
    "–î–∞–Ω–Ω—ã–µ ‚Üí –í–∞–ª–∏–¥–∞—Ü–∏—è ‚Üí EDA ‚Üí –§–∏—á–∏/–ü–∞–π–ø–ª–∞–π–Ω ‚Üí –¢—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞/–í–∞–ª–∏–¥–∞—Ü–∏—è ‚Üí –¢—Ä–µ–∫–∏–Ω–≥ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤\n",
    "      ‚Üí –≠–∫—Å–ø–æ—Ä—Ç –º–æ–¥–µ–ª–∏ ‚Üí API (–æ–Ω–ª–∞–π–Ω) + Batch (–æ—Ñ–ª–∞–π–Ω) ‚Üí –ö–æ–Ω—Ç–µ–π–Ω–µ—Ä–∏–∑–∞—Ü–∏—è ‚Üí –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥/–î—Ä–∏—Ñ—Ç\n",
    "```\n",
    "\n",
    "–°—Ç–µ–∫ (—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏):\n",
    "- Python 3.9+; NumPy, Pandas, scikit‚Äëlearn.\n",
    "- MLflow (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ), FastAPI (–¥–ª—è API), Uvicorn (–ª–æ–∫–∞–ª—å–Ω—ã–π —Å–µ—Ä–≤–µ—Ä).\n",
    "- Docker (—à–∞–±–ª–æ–Ω), pytest (–º–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ —Ç–µ—Å—Ç—ã).\n",
    "\n",
    "üí° –ú–æ–∂–Ω–æ –∑–∞–º–µ–Ω–∏—Ç—å –¥–æ–º–µ–Ω (–Ω–∞–ø—Ä–∏–º–µ—Ä, –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–æ, –æ—Ç–∫–∞–∑—ã –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è), –Ω–æ —Å–æ—Ö—Ä–∞–Ω–∏—Ç–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—É MLOps.\n"
   ],
   "id": "726082a8fa950160"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## üöÄ –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç\n",
    "1. –ü–æ–¥–≥–æ—Ç–æ–≤—å—Ç–µ –¥–∞—Ç–∞—Å–µ—Ç `data/raw/churn.csv` (–∏–ª–∏ –∞–Ω–∞–ª–æ–≥–∏—á–Ω—ã–π —Ç–∞–±–ª–∏—á–Ω—ã–π): —Ü–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è `churn` (0/1).\n",
    "2. –ó–∞–ø–æ–ª–Ω–∏—Ç–µ –ø—É—Ç–∏ –≤ —è—á–µ–π–∫–∞—Ö –Ω–∏–∂–µ (data/raw, data/processed).\n",
    "3. –ü–æ –∂–µ–ª–∞–Ω–∏—é –≤–∫–ª—é—á–∏—Ç–µ MLflow (—É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ `pip install mlflow`).\n",
    "4. –î–ª—è API –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ FastAPI (—É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ `pip install fastapi uvicorn pydantic`).\n",
    "\n",
    "üèÅ –¶–µ–ª—å ‚Äî –ø–æ–ª—É—á–∏—Ç—å —Ä–∞–±–æ—Ç–∞—é—â–∏–π –ø—Ä–æ—Ç–æ—Ç–∏–ø –∏ —á–µ–∫‚Äë–ª–∏—Å—Ç—ã –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–π –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏.\n"
   ],
   "id": "ced18e15d76cbf05"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# üõ†Ô∏è –ò–º–ø–æ—Ä—Ç—ã –∏ –±–∞–∑–æ–≤—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# –í–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç—å\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# –ü—É—Ç–∏ –ø—Ä–æ–µ–∫—Ç–∞ (–º–æ–∂–Ω–æ –º–µ–Ω—è—Ç—å –ø–æ–¥ —Å–µ–±—è)\n",
    "BASE_DIR = Path.cwd()\n",
    "DATA_DIR = BASE_DIR / 'data'\n",
    "RAW_DIR = DATA_DIR / 'raw'\n",
    "PROCESSED_DIR = DATA_DIR / 'processed'\n",
    "MODELS_DIR = BASE_DIR / 'models'\n",
    "ARTIFACTS_DIR = BASE_DIR / 'artifacts'\n",
    "for p in [DATA_DIR, RAW_DIR, PROCESSED_DIR, MODELS_DIR, ARTIFACTS_DIR]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print('–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –∫–∞—Ç–∞–ª–æ–≥–æ–≤ –≥–æ—Ç–æ–≤–∞:', DATA_DIR, MODELS_DIR, ARTIFACTS_DIR)\n"
   ],
   "id": "7fe0287a087b3495"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## üì• 1. –ü–æ–ª—É—á–µ–Ω–∏–µ –∏ –∑–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
    "–ü–æ–¥–≥–æ—Ç–æ–≤—å—Ç–µ —Ñ–∞–π–ª `data/raw/churn.csv` —Å–æ —Å—Ç–æ–ª–±—Ü–∞–º–∏: –ø—Ä–∏–∑–Ω–∞–∫–∏ (—á–∏—Å–ª–æ–≤—ã–µ/–∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ) –∏ —Ü–µ–ª–µ–≤–∞—è `churn` (0/1).\n",
    "\n",
    "–ü—Ä–∏–º–µ—Ä—ã –ø—É–±–ª–∏—á–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤: Kaggle (Telco Customer Churn).\n",
    "\n",
    "–ü–æ–¥—Å–∫–∞–∑–∫–∏:\n",
    "- –ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã —Ö—Ä–∞–Ω–∏—Ç–µ –≤ `object`/`category`.\n",
    "- –î–∞—Ç–∞/–≤—Ä–µ–º—è ‚Äî –ø—Ä–µ–æ–±—Ä–∞–∑—É–π—Ç–µ –≤ datetime.\n"
   ],
   "id": "f4c3e2aae51b8904"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# üß© –í–∞—à –∫–æ–¥: –∑–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
    "csv_path = RAW_DIR / 'churn.csv'\n",
    "if csv_path.exists():\n",
    "    df = pd.read_csv(csv_path)\n",
    "    display(df.head())\n",
    "    print(df.shape)\n",
    "else:\n",
    "    print('‚ö†Ô∏è –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω:', csv_path)\n",
    "    # –î–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ —Å–æ–∑–¥–∞–¥–∏–º —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ\n",
    "    n = 2000\n",
    "    df = pd.DataFrame({\n",
    "        'age': np.random.randint(18, 80, size=n),\n",
    "        'tenure_months': np.random.randint(1, 72, size=n),\n",
    "        'plan_type': np.random.choice(['basic','pro','enterprise'], size=n, p=[0.6,0.3,0.1]),\n",
    "        'monthly_fee': np.round(np.random.uniform(5, 80, size=n), 2),\n",
    "        'country': np.random.choice(['UZ','RU','KZ','KG','TJ'], size=n),\n",
    "        'support_tickets_90d': np.random.poisson(1.4, size=n),\n",
    "        'churn': np.random.binomial(1, 0.25, size=n)\n",
    "    })\n",
    "    display(df.head())\n",
    "    print('–°–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–π –Ω–∞–±–æ—Ä:', df.shape)\n",
    "\n",
    "# –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∫–∞–∫ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π –∞—Ä—Ç–µ—Ñ–∞–∫—Ç\n",
    "PROCESSED_DIR.mkdir(exist_ok=True, parents=True)\n",
    "df.to_csv(PROCESSED_DIR / 'churn_raw_loaded.csv', index=False)\n",
    "print('‚úÖ –î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ processed.')\n"
   ],
   "id": "c947b32cf5070b5f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## ‚úÖ 2. –ë–∞–∑–æ–≤–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö (Data Validation)\n",
    "–ü—Ä–æ–≤–µ—Ä–∏–º —Ç–∏–ø—ã, –ø—Ä–æ–ø—É—Å–∫–∏, —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏, –±–∞–∑–æ–≤—ã–µ –∏–Ω–≤–∞—Ä–∏–∞–Ω—Ç—ã. –≠—Ç–æ –∏–º–∏—Ç–∞—Ü–∏—è data checks, –∫–æ—Ç–æ—Ä—ã–µ –≤—ã –≤—ã–Ω–µ—Å–µ—Ç–µ –≤ –ø–∞–π–ø–ª–∞–π–Ω/CI.\n"
   ],
   "id": "8fe31c6454dac34b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# –ü—Ä–æ–≤–µ—Ä–∫–∏\n",
    "assert 'churn' in df.columns, '–ù–µ—Ç —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π churn'\n",
    "print('–¢–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö:')\n",
    "display(df.dtypes)\n",
    "print('–ü—Ä–æ–ø—É—Å–∫–∏ –ø–æ —Å—Ç–æ–ª–±—Ü–∞–º:')\n",
    "display(df.isna().sum())\n",
    "\n",
    "# –ü—Ä–∏–º–µ—Ä –∏–Ω–≤–∞—Ä–∏–∞–Ω—Ç–æ–≤\n",
    "if 'age' in df.columns:\n",
    "    assert (df['age'] >= 0).all(), '–í–æ–∑—Ä–∞—Å—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è'\n",
    "if 'monthly_fee' in df.columns:\n",
    "    assert (df['monthly_fee'] >= 0).all(), '–¢–∞—Ä–∏—Ñ —Å–æ–¥–µ—Ä–∂–∏—Ç –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è'\n",
    "print('‚úÖ –ë–∞–∑–æ–≤—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø—Ä–æ–π–¥–µ–Ω—ã (–∏–ª–∏ –ø—Ä–æ–≤–∞–ª—è—Ç—Å—è —Å –ø–æ–ª–µ–∑–Ω—ã–º —Å–æ–æ–±—â–µ–Ω–∏–µ–º).')\n"
   ],
   "id": "a9833b5bfac12c5b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## üîé 3. –ë—ã—Å—Ç—Ä—ã–π EDA\n",
    "–°–≤–æ–¥–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞, —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è, —Ü–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è, –ø–µ—Ä–µ–∫–æ—Å –∫–ª–∞—Å—Å–æ–≤, –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ —á–∏—Å–ª–æ–≤—ã—Ö.\n",
    "\n",
    "–ü–æ–¥—Å–∫–∞–∑–∫–∏: –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ `df.describe()`, `value_counts()`, `corr()`.\n"
   ],
   "id": "8babd3109ee43f66"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "display(df.describe(include='all'))\n",
    "if 'churn' in df.columns:\n",
    "    print('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π:')\n",
    "    display(df['churn'].value_counts(normalize=True))\n",
    "print('–ß–∏—Å–ª–æ–≤–∞—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è:')\n",
    "display(df.select_dtypes(include=np.number).corr())\n",
    "print('üî• EDA –±–∞–∑–æ–≤–æ –≤—ã–ø–æ–ª–Ω–µ–Ω. –ü—Ä–æ–¥–æ–ª–∂–∏—Ç–µ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏.')\n"
   ],
   "id": "b6e262f02c59d689"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## üß™ 4. –§–∏—á–∏ –∏ ML‚Äë–ø–∞–π–ø–ª–∞–π–Ω (sklearn Pipeline)\n",
    "- –†–∞–∑–¥–µ–ª–∏—Ç–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –Ω–∞ —á–∏—Å–ª–æ–≤—ã–µ –∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ.\n",
    "- –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ —á–∏—Å–ª–æ–≤—ã—Ö, One‚ÄëHot –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö.\n",
    "- –ú–æ–¥–µ–ª—å: LogisticRegression / RandomForest / XGBoost (–ø—Ä–∏ –Ω–∞–ª–∏—á–∏–∏).\n",
    "- –ö—Ä–æ—Å—Å‚Äë–≤–∞–ª–∏–¥–∞—Ü–∏—è –∏ –ø–æ–¥–±–æ—Ä –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤.\n",
    "\n",
    "–ü–æ–¥—Å–∫–∞–∑–∫–∞: `ColumnTransformer`, `Pipeline`, `GridSearchCV`.\n"
   ],
   "id": "cfeccb7eeb33286"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "\n",
    "target_col = 'churn'\n",
    "y = df[target_col].astype(int)\n",
    "X = df.drop(columns=[target_col])\n",
    "\n",
    "num_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols = X.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "numeric_pipe = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "categorical_pipe = Pipeline(steps=[('ohe', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_pipe, num_cols),\n",
    "        ('cat', categorical_pipe, cat_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "model = LogisticRegression(max_iter=200, random_state=RANDOM_STATE)\n",
    "clf = Pipeline(steps=[('prep', preprocess), ('model', model)])\n",
    "\n",
    "param_grid = {\n",
    "    'model__C': [0.1, 1.0, 5.0],\n",
    "    'model__penalty': ['l2']\n",
    "}\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "search = GridSearchCV(clf, param_grid, scoring='roc_auc', cv=cv, n_jobs=-1, verbose=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=RANDOM_STATE)\n",
    "search.fit(X_train, y_train)\n",
    "print('–õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:', search.best_params_)\n",
    "print('–õ—É—á—à–∏–π AUC (CV):', search.best_score_)\n",
    "best_model = search.best_estimator_\n",
    "pred_proba = best_model.predict_proba(X_test)[:,1]\n",
    "auc = roc_auc_score(y_test, pred_proba)\n",
    "print('AUC (test):', round(auc, 4))\n",
    "print(classification_report(y_test, (pred_proba>0.5).astype(int)))\n",
    "\n",
    "# –°–æ—Ö—Ä–∞–Ω–∏–º –º–µ—Ç—Ä–∏–∫–∏\n",
    "metrics = {'auc_test': float(auc)}\n",
    "with open(ARTIFACTS_DIR / 'metrics.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(metrics, f, ensure_ascii=False, indent=2)\n",
    "print('‚úÖ –ú–µ—Ç—Ä–∏–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ artifacts/metrics.json')\n"
   ],
   "id": "10b5e7b753d179b5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## üìí 5. –¢—Ä–µ–∫–∏–Ω–≥ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ MLflow)\n",
    "–ï—Å–ª–∏ MLflow —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –∑–∞—Ñ–∏–∫—Å–∏—Ä—É–π—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã/–º–µ—Ç—Ä–∏–∫–∏/–∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã.\n",
    "\n",
    "–ü–æ–¥—Å–∫–∞–∑–∫–∞: –ø–µ—Ä–µ–¥ –∑–∞–ø—É—Å–∫–æ–º –º–æ–∂–Ω–æ –ø–æ–¥–Ω—è—Ç—å UI: `mlflow ui` (–ª–æ–∫–∞–ª—å–Ω–æ).\n"
   ],
   "id": "c16ee7afbf065082"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# üß© –í–∞—à –∫–æ–¥: –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ MLflow (–Ω–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ)\n",
    "try:\n",
    "    import mlflow\n",
    "    import mlflow.sklearn\n",
    "    mlflow.set_experiment('churn_capstone')\n",
    "    with mlflow.start_run(run_name='logreg_grid'):\n",
    "        mlflow.log_params(search.best_params_)\n",
    "        mlflow.log_metrics({'auc_test': float(auc)})\n",
    "        # –õ–æ–≥–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å (–∞—Ä—Ç–µ—Ñ–∞–∫—Ç)\n",
    "        mlflow.sklearn.log_model(best_model, artifact_path='model')\n",
    "    print('‚úÖ –õ–æ–≥–∏ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω—ã –≤ MLflow')\n",
    "except Exception as e:\n",
    "    print('‚ÑπÔ∏è MLflow –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –∏–ª–∏ –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º. –ü—Ä–∏—á–∏–Ω–∞:', e)\n"
   ],
   "id": "555972a5b93aa72a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## üì¶ 6. –≠–∫—Å–ø–æ—Ä—Ç –º–æ–¥–µ–ª–∏ (–∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã)\n",
    "–°–æ—Ö—Ä–∞–Ω–∏–º –ø–∞–π–ø–ª–∞–π–Ω + –≤–µ—Å–∞ –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞.\n"
   ],
   "id": "afc57550e1671a0a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import joblib\n",
    "model_path = MODELS_DIR / 'churn_pipeline.joblib'\n",
    "joblib.dump(best_model, model_path)\n",
    "print('‚úÖ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤', model_path)\n",
    "# –°–æ—Ö—Ä–∞–Ω–∏–º —Å—Ö–µ–º—É —Ñ–∏—á–µ–π (–ø–æ—Ç—Ä–µ–±—É–µ—Ç—Å—è –¥–ª—è API/Batch)\n",
    "feature_schema = {'num': num_cols, 'cat': cat_cols}\n",
    "with open(MODELS_DIR / 'feature_schema.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(feature_schema, f, ensure_ascii=False, indent=2)\n",
    "print('‚úÖ –°—Ö–µ–º–∞ —Ñ–∏—á–µ–π —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞.')\n"
   ],
   "id": "c71139dc26c58db3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## üåê 7. REST‚ÄëAPI (FastAPI) ‚Äî —á–µ—Ä–Ω–æ–≤–∏–∫ —Å–µ—Ä–≤–∏—Å–∞ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞\n",
    "–≠—Ç–æ—Ç –∫–æ–¥ –º–æ–∂–Ω–æ –≤—ã–Ω–µ—Å—Ç–∏ –≤ `app.py`. –ó–¥–µ—Å—å ‚Äî –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø—Ä–∏–º–µ—Ä.\n",
    "\n",
    "–ö–æ–º–∞–Ω–¥–∞ –∑–∞–ø—É—Å–∫–∞ (–ª–æ–∫–∞–ª—å–Ω–æ):\n",
    "```\n",
    "uvicorn app:app --host 0.0.0.0 --port 8000\n",
    "```\n"
   ],
   "id": "ec8844f267dd9f35"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# –ü—Ä–∏–º–µ—Ä FastAPI –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è (–Ω–µ –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤ –Ω–æ—É—Ç–±—É–∫–µ)\n",
    "from typing import List, Optional\n",
    "try:\n",
    "    from fastapi import FastAPI\n",
    "    from pydantic import BaseModel\n",
    "    _FASTAPI_AVAILABLE = True\n",
    "except Exception:\n",
    "    _FASTAPI_AVAILABLE = False\n",
    "\n",
    "class ChurnRequest(BaseModel):\n",
    "    # –£–ø—Ä–æ—Å—Ç–∏–º: –ø—Ä–∏–Ω–∏–º–∞–µ–º –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –Ω–∞ —Å—Ç—Ä–æ–∫—É\n",
    "    records: List[dict]\n",
    "\n",
    "if _FASTAPI_AVAILABLE:\n",
    "    app = FastAPI(title='Churn Inference API')\n",
    "    _pipeline = joblib.load(model_path) if os.path.exists(model_path) else None\n",
    "\n",
    "    @app.get('/')\n",
    "    def root():\n",
    "        return {'status': 'ok'}\n",
    "\n",
    "    @app.post('/predict')\n",
    "    def predict(req: ChurnRequest):\n",
    "        import pandas as pd\n",
    "        df_in = pd.DataFrame(req.records)\n",
    "        proba = _pipeline.predict_proba(df_in)[:,1] if _pipeline is not None else []\n",
    "        return {'proba': [float(x) for x in proba]}\n",
    "else:\n",
    "    print('‚ÑπÔ∏è FastAPI –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –ü—Ä–æ–ø—É—Å—Ç–∏—Ç–µ –∏–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install fastapi uvicorn pydantic')\n"
   ],
   "id": "1ff041a3117ab27a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## üìö 8. –ü–∞–∫–µ—Ç–Ω—ã–π –∏–Ω—Ñ–µ—Ä–µ–Ω—Å (Batch)\n",
    "–°–∫—Ä–∏–ø—Ç, –∫–æ—Ç–æ—Ä—ã–π —á–∏—Ç–∞–µ—Ç CSV –∏ –ø–∏—à–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—è–º–∏.\n"
   ],
   "id": "54fc742bef98fb35"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# üß© –í–∞—à –∫–æ–¥: –ø–∞–∫–µ—Ç–Ω—ã–π –∏–Ω—Ñ–µ—Ä–µ–Ω—Å\n",
    "def batch_infer(input_csv: Path, output_csv: Path, model_file: Path = model_path):\n",
    "    pipe = joblib.load(model_file)\n",
    "    data = pd.read_csv(input_csv)\n",
    "    probs = pipe.predict_proba(data)[:,1]\n",
    "    out = data.copy()\n",
    "    out['churn_proba'] = probs\n",
    "    out.to_csv(output_csv, index=False)\n",
    "    return len(out)\n",
    "\n",
    "# –ü—Ä–∏–º–µ—Ä (—Ä–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ, –µ—Å–ª–∏ –µ—Å—Ç—å —Ñ–∞–π–ª):\n",
    "# batch_infer(PROCESSED_DIR / 'scoring_input.csv', ARTIFACTS_DIR / 'scoring_output.csv')\n",
    "print('‚úÖ –®–∞–±–ª–æ–Ω –ø–∞–∫–µ—Ç–Ω–æ–≥–æ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ –≥–æ—Ç–æ–≤.')\n"
   ],
   "id": "2f692df12c54041e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## üì¶ 9. –ö–æ–Ω—Ç–µ–π–Ω–µ—Ä–∏–∑–∞—Ü–∏—è ‚Äî Dockerfile (—à–∞–±–ª–æ–Ω)\n",
    "–§–∞–π–ª `Dockerfile` (—Å–æ—Ö—Ä–∞–Ω–∏—Ç–µ –æ—Ç–¥–µ–ª—å–Ω–æ –≤ –∫–æ—Ä–Ω–µ –ø—Ä–æ–µ–∫—Ç–∞):\n",
    "\n",
    "```\n",
    "FROM python:3.10-slim\n",
    "WORKDIR /app\n",
    "COPY requirements.txt ./\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "COPY . .\n",
    "EXPOSE 8000\n",
    "CMD [\"uvicorn\", \"app:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n",
    "```\n",
    "\n",
    "–ü—Ä–∏–º–µ—Ä `requirements.txt`:\n",
    "```\n",
    "numpy\n",
    "pandas\n",
    "scikit-learn\n",
    "joblib\n",
    "fastapi\n",
    "uvicorn\n",
    "mlflow  # –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ\n",
    "```\n"
   ],
   "id": "8c3296f55d1c02c0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## üß™ 10. –¢–µ—Å—Ç—ã –∏ CI (—á–µ—Ä–Ω–æ–≤–∏–∫)\n",
    "–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π `pytest`‚Äë—Ç–µ—Å—Ç –¥–ª—è API/–º–æ–¥–µ–ª–∏ (—Å–æ—Ö—Ä–∞–Ω–∏—Ç–µ –∫–∞–∫ `tests/test_infer.py`):\n",
    "\n",
    "```\n",
    "import joblib, pandas as pd, numpy as np\n",
    "\n",
    "def test_model_load_and_predict():\n",
    "    model = joblib.load('models/churn_pipeline.joblib')\n",
    "    df = pd.DataFrame([{'age':30,'tenure_months':12,'plan_type':'basic','monthly_fee':20,'country':'UZ','support_tickets_90d':0}])\n",
    "    proba = model.predict_proba(df)[:,1]\n",
    "    assert np.isfinite(proba).all()\n",
    "```\n",
    "\n",
    "CI –∏–¥–µ–∏: –∑–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤ –∏ –ª–∏–Ω—Ç–µ—Ä–æ–≤ –Ω–∞ PR, —Å–±–æ—Ä Docker‚Äë–æ–±—Ä–∞–∑–∞, –≤—ã–≥—Ä—É–∑–∫–∞ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤.\n"
   ],
   "id": "7be8a5017a166a71"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## ü©∫ 11. –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ –¥—Ä–µ–π—Ñ –¥–∞–Ω–Ω—ã—Ö (—á–µ—Ä–Ω–æ–≤–∏–∫)\n",
    "–ü—Ä–∏–º–µ—Ä –≥—Ä—É–±–æ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π (KS‚Äë—Ç–µ—Å—Ç) –º–µ–∂–¥—É –æ–±—É—á–∞—é—â–µ–π –∏ –ø—Ä–æ–¥–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∞–º–∏.\n",
    "\n",
    "–ü–æ–¥—Å–∫–∞–∑–∫–∞: –¥–ª—è –ø—Ä–æ–¥–∞–∫—à–Ω–∞ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∞–ª–µ—Ä—Ç—ã, –¥–∞—à–±–æ—Ä–¥—ã, —Ö—Ä–∞–Ω–∏—Ç–µ –±–∞–∑–æ–≤—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É (feature store).\n"
   ],
   "id": "386a18d427f5e71b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# üß© –í–∞—à –∫–æ–¥: –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥\n",
    "def ks_drift_stat(ref: pd.Series, cur: pd.Series):\n",
    "    # –ü—Ä–æ—Å—Ç–µ–π—à–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è —á–µ—Ä–µ–∑ —ç–º–ø–∏—Ä–∏—á–µ—Å–∫–∏–µ CDF\n",
    "    ref_sorted = np.sort(ref.dropna().values)\n",
    "    cur_sorted = np.sort(cur.dropna().values)\n",
    "\n",
    "    # —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å–µ—Ç–∫–∞\n",
    "    grid = np.unique(np.concatenate([ref_sorted, cur_sorted]))\n",
    "    def ecdf(x, grid):\n",
    "        return np.searchsorted(x, grid, side='right') / len(x)\n",
    "    d = np.max(np.abs(ecdf(ref_sorted, grid) - ecdf(cur_sorted, grid)))\n",
    "    return float(d)\n",
    "\n",
    "# –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –Ω–∞ 'monthly_fee' (—Ä–µ—Ñ ‚Äî train, cur ‚Äî test)\n",
    "if 'monthly_fee' in X_train.columns:\n",
    "    d_stat = ks_drift_stat(X_train['monthly_fee'], X_test['monthly_fee'])\n",
    "    print('KS drift stat (monthly_fee):', round(d_stat, 4))\n",
    "    if d_stat > 0.2:\n",
    "        print('‚ö†Ô∏è –í–æ–∑–º–æ–∂–Ω—ã–π –¥—Ä–µ–π—Ñ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è!')\n",
    "    else:\n",
    "        print('‚úÖ –î—Ä–µ–π—Ñ –≤ –¥–æ–ø—É—Å—Ç–∏–º—ã—Ö –ø—Ä–µ–¥–µ–ª–∞—Ö (—ç–≤—Ä–∏—Å—Ç–∏–∫–∞).')\n",
    "else:\n",
    "    print('‚ÑπÔ∏è –ü–æ–ª–µ monthly_fee –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ —Ç–∞–±–ª–∏—á–Ω—ã—Ö —Ñ–∏—á–∞—Ö.')\n"
   ],
   "id": "5eed78038ee412e4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## üö¢ 12. –ü–ª–∞–Ω –¥–µ–ø–ª–æ—è (—à–∞–±–ª–æ–Ω)\n",
    "- –°–±–æ—Ä–∫–∞ Docker –æ–±—Ä–∞–∑–∞, –ø—É—à –≤ registry.\n",
    "- –†–∞–∑–≤—ë—Ä—Ç—ã–≤–∞–Ω–∏–µ –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–Ω—ã–π –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä (Kubernetes/managed).\n",
    "- –ö–æ–Ω—Ñ–∏–≥ —Å–µ–∫—Ä–µ—Ç–∞/–ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è (–ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ, —Ç—Ä–µ–∫–∏–Ω–≥).\n",
    "- –ü—Ä–æ–∫—Å–∏/ingress –¥–ª—è API, –∞–≤—Ç–æ‚Äë–º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ.\n",
    "- –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥: –ª–æ–≥‚Äë–∞–≥—Ä–µ–≥–∞—Ü–∏—è, –º–µ—Ç—Ä–∏–∫–∏ (latency, throughput, –æ—à–∏–±–∫–∏), –¥—Ä–µ–π—Ñ —Ñ–∏—á–µ–π.\n",
    "- –ö–∞–Ω–∞—Ä–µ–µ—á–Ω—ã–π/blue‚Äëgreen –¥–µ–ø–ª–æ–π.\n",
    "- –û–±—Ä–∞—Ç–Ω–∞—è —Å–≤—è–∑—å –∏ —Ü–∏–∫–ª –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è.\n"
   ],
   "id": "aa30ab83db130256"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## üî• –°–ª–æ–∂–Ω—ã–µ –∑–∞–¥–∞–Ω–∏—è (–¥–ª—è –ø—Ä–æ–∫–∞—á–∫–∏)\n",
    "1. –ó–∞–º–µ–Ω–∏—Ç–µ LogisticRegression –Ω–∞ CatBoost/XGBoost/LightGBM —Å –ø–æ–∏—Å–∫–æ–º –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤.\n",
    "2. –í—ã–Ω–µ—Å–∏—Ç–µ —Ñ–∏—á–µ–ø–∞–π–ø–ª–∞–π–Ω –≤ –º–æ–¥—É–ª—å –∏ –¥–æ–±–∞–≤—å—Ç–µ unit‚Äë—Ç–µ—Å—Ç—ã –Ω–∞ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä—ã.\n",
    "3. –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω—ã–π MLflow (—Ç—Ä–µ–∫–µ—Ä/–∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã), –¥–æ–±–∞–≤—å—Ç–µ –º–æ–¥–µ–ª—å–Ω—ã–π —Ä–µ–µ—Å—Ç—Ä.\n",
    "4. –°–æ–±–µ—Ä–∏—Ç–µ Docker‚Äë–æ–±—Ä–∞–∑ –∏ –ø–æ–¥–Ω–∏–º–∏—Ç–µ API –ª–æ–∫–∞–ª—å–Ω–æ —á–µ—Ä–µ–∑ docker run.\n",
    "5. –î–æ–±–∞–≤—å—Ç–µ –º–µ—Ç—Ä–∏–∫–∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –∏ –∞–ª–µ—Ä—Ç—ã (Prometheus/Grafana, Sentry).\n",
    "6. –†–µ–∞–ª–∏–∑—É–π—Ç–µ –ø—Ä–æ—Å—Ç—É—é –ø—Ä–æ–≤–µ—Ä–∫—É –¥–∞–Ω–Ω—ã—Ö –Ω–∞ –≤—Ö–æ–¥–µ API (pydantic —Å—Ö–µ–º—ã, —Å—Ç—Ä–æ–≥–∏–µ —Ç–∏–ø—ã).\n",
    "7. –ü—Ä–∏–º–µ–Ω–∏—Ç–µ –º–æ–¥–µ–ª—å –∫ –∂–∏–≤–æ–º—É –ø–æ—Ç–æ–∫—É (–∏–º–∏—Ç–∞—Ü–∏—è —á–µ—Ä–µ–∑ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ/—Å—Ç—Ä–∏–º).\n",
    "8. –ù–∞—Å—Ç—Ä–æ–π—Ç–µ CI (GitHub Actions/GitLab CI): –ª–∏–Ω—Ç–µ—Ä—ã, —Ç–µ—Å—Ç—ã, —Å–±–æ—Ä–∫–∞ –æ–±—Ä–∞–∑–∞, –ø—É—à.\n",
    "9. –†–µ–∞–ª–∏–∑—É–π—Ç–µ –æ—Ü–µ–Ω–∫—É —ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–æ–≥–æ —ç—Ñ—Ñ–µ–∫—Ç–∞ (business metrics).\n",
    "10. –î–æ–±–∞–≤—å—Ç–µ A/B —Ç–µ—Å—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –Ω–∞ –ø–æ–¥–º–Ω–æ–∂–µ—Å—Ç–≤–µ —Ç—Ä–∞—Ñ–∏–∫–∞.\n",
    "\n",
    "üèÜ –ü–æ—Å–ª–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –≤—ã –ø–æ–ª—É—á–∏—Ç–µ –ø—Ä–æ–µ–∫—Ç, –ø–æ—Ö–æ–∂–∏–π –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã–µ –∑–∞–¥–∞—á–∏ AI Engineer/MLOps.\n",
    "üî• –û—Ç–ª–∏—á–Ω–∞—è —Ä–∞–±–æ—Ç–∞!\n"
   ],
   "id": "cd0fc724c29dcf9d"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
